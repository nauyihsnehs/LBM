# wandb
wandb_project: lbm-fill-lighting
backbone_signature: stable-diffusion-v1-5/stable-diffusion-v1-5
unet_input_channels: 10
vae_num_channels: 4
timestep_sampling: custom_timesteps
selected_timesteps: [ 250, 500, 750, 1000 ]
prob: [ 0.25, 0.25, 0.25, 0.25 ]
pixel_loss_type: lpips
pixel_loss_weight: 10.0
latent_loss_type: l2
latent_loss_weight: 1.0
bridge_noise_sigma: 0.005
conditioning_images_keys: [ shading ]
conditioning_masks_keys: [ depth, lighting_scale ]
lighting_embedder_config:
  mapping_size: 256
  scale: 10.0
  hidden_dim: 512
  out_dim: 768
  seq_len: 1
source_key: source
target_key: target

# DATA ROOTS
train_data_root: /mnt/data1/ssy/render_people/fill-light-dataset/train
validation_data_root: /mnt/data1/ssy/render_people/fill-light-dataset/val
image_size: 512
num_workers: 4
train_random_flip: true

batch_size: 2
learning_rate: 4e-5
optimizer: AdamW
num_steps: [ 1, 4 ]
log_interval: 500
resume_from_checkpoint: true
max_epochs: 10
save_interval: 10000
resume_ckpt_path: null
save_ckpt_path: ./checkpoints
